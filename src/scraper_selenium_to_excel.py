#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Trendyol SatÄ±cÄ± SayfasÄ± Scraper - Excel Raporu
==============================================

KULLANIM:
1. python -m venv .venv
2. .venv\Scripts\activate.bat
3. pip install -r requirements.txt
4. tools\ klasÃ¶rÃ¼ne chromedriver.exe dosyasÄ±nÄ± koyun
5. python src\scraper_selenium_to_excel.py

UYARI: Demo amaÃ§lÄ±, dÃ¼ÅŸÃ¼k frekanslÄ± istekler ile kullanÄ±n. 
BÃ¼yÃ¼k Ã¶lÃ§ek veya ticari kullanÄ±m iÃ§in Trendyol izinlerini kontrol edin.

Bu script Trendyol satÄ±cÄ± sayfasÄ±ndan Ã¼rÃ¼n bilgilerini toplar ve Excel raporu oluÅŸturur.
"""

import os
import sys
import json
import time
import random
import pandas as pd
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException
from urllib.parse import urljoin, urlparse
import requests
from bs4 import BeautifulSoup

# Windows terminal encoding dÃ¼zeltme
if sys.platform == 'win32':
    os.environ['PYTHONIOENCODING'] = 'utf-8'
    sys.stdout.reconfigure(encoding='utf-8')

# YardÄ±mcÄ± modÃ¼lleri import et (src klasÃ¶rÃ¼ ekleniyor)
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
from src.image_analyzer import is_mockup_by_filename
from src.report_generator import generate_excel_report

# =============================================================================
# KONFIGÃœRASYON AYARLARI
# =============================================================================

# ChromeDriver yolu (kullanÄ±cÄ± tools/ klasÃ¶rÃ¼ne chromedriver.exe koyacak)
CHROMEDRIVER_PATH = os.path.join("tools", "chromedriver.exe")

# Demo iÃ§in tarayÄ±cÄ±yÄ± gÃ¶ster (False = gÃ¶rÃ¼nÃ¼r, True = gizli)
HEADLESS = False

# Maksimum Ã¼rÃ¼n sayÄ±sÄ± (demo iÃ§in hÄ±zlÄ± test)
MAX_PRODUCTS = 10

# Beklenen Ã¶lÃ§Ã¼ler (eksik Ã¶lÃ§Ã¼ analizi iÃ§in)
# Bu Ã¶lÃ§Ã¼ler satÄ±cÄ±nÄ±n her Ã¼rÃ¼nde olmasÄ± beklenen Ã¶lÃ§Ã¼lerdir
# Otomatik olarak tÃ¼m Ã¶lÃ§Ã¼ler tarandÄ±ÄŸÄ± iÃ§in, 
# burada hangi Ã¶lÃ§Ã¼lerin eksik olduÄŸunu raporlarda gÃ¶receksiniz
EXPECTED_SIZES = ["30x40", "40x60", "50x70", "20x30", "60x90"]

# Mockup tespiti iÃ§in anahtar kelimeler
MOCKUP_KEYWORDS = ["mockup", "mokap", "frame", "psd", "mock"]

# Rastgele bekleme sÃ¼releri (saniye)
WAIT_MIN = 1.0
WAIT_MAX = 2.5

# Maksimum retry sayÄ±sÄ±
MAX_RETRIES = 3

# =============================================================================
# YARDIMCI FONKSÄ°YONLAR
# =============================================================================

def human_wait():
    """Ä°nsan benzeri rastgele bekleme"""
    wait_time = random.uniform(WAIT_MIN, WAIT_MAX)
    print(f"â³ {wait_time:.1f} saniye bekleniyor...")
    time.sleep(wait_time)

def init_driver():
    """
    ChromeDriver ile tarayÄ±cÄ± baÅŸlatma
    User-agent ve timeout ayarlarÄ± ile
    """
    print("ğŸš€ ChromeDriver baÅŸlatÄ±lÄ±yor...")
    
    # Chrome seÃ§enekleri
    chrome_options = Options()
    
    if HEADLESS:
        chrome_options.add_argument("--headless")
    
    # User-agent ekle (bot tespitini zorlaÅŸtÄ±rÄ±r)
    chrome_options.add_argument("--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
    
    # DiÄŸer ayarlar
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--disable-blink-features=AutomationControlled")
    chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
    chrome_options.add_experimental_option('useAutomationExtension', False)
    
    # ChromeDriver servisi
    service = Service(CHROMEDRIVER_PATH)
    
    try:
        driver = webdriver.Chrome(service=service, options=chrome_options)
        
        # JavaScript ile navigator.webdriver Ã¶zelliÄŸini gizle
        driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
        
        # Timeout ayarlarÄ±
        driver.implicitly_wait(10)
        driver.set_page_load_timeout(30)
        
        print("âœ… ChromeDriver baÅŸarÄ±yla baÅŸlatÄ±ldÄ±")
        return driver
        
    except Exception as e:
        print(f"âŒ ChromeDriver baÅŸlatma hatasÄ±: {e}")
        print("ğŸ’¡ tools/ klasÃ¶rÃ¼nde chromedriver.exe dosyasÄ±nÄ±n olduÄŸundan emin olun")
        raise

def collect_product_links_from_seller(driver, seller_url, max_pages=30, max_products=MAX_PRODUCTS):
    """
    SatÄ±cÄ± sayfasÄ±ndan Ã¼rÃ¼n linklerini toplar
    Sayfalama ile Ã§alÄ±ÅŸÄ±r ve maksimum Ã¼rÃ¼n sayÄ±sÄ±na kadar toplar
    """
    print(f"ğŸ” SatÄ±cÄ± sayfasÄ±ndan Ã¼rÃ¼n linkleri toplanÄ±yor: {seller_url}")
    
    product_links = []
    page = 1
    
    while page <= max_pages and len(product_links) < max_products:
        try:
            # Sayfa URL'si oluÅŸtur
            if page == 1:
                page_url = seller_url
            else:
                page_url = f"{seller_url}?sayfa={page}"
            
            print(f"ğŸ“„ Sayfa {page} iÅŸleniyor: {page_url}")
            
            # SayfayÄ± yÃ¼kle
            driver.get(page_url)
            human_wait()
            
            # ÃœrÃ¼n linklerini bul (birden fazla CSS seÃ§ici dene)
            selectors = [
                "a.p-card-chld",  # Ana Ã¼rÃ¼n kartlarÄ±
                "a[href*='/p/']",  # ÃœrÃ¼n linkleri
                ".p-card a",  # Alternatif seÃ§ici
                "[data-testid='product-card'] a"  # Test ID ile
            ]
            
            links_found = []
            for selector in selectors:
                try:
                    elements = driver.find_elements(By.CSS_SELECTOR, selector)
                    for element in elements:
                        href = element.get_attribute("href")
                        if href and "/p/" in href and href not in links_found:
                            links_found.append(href)
                    
                    if links_found:
                        print(f"âœ… {len(links_found)} Ã¼rÃ¼n linki bulundu (seÃ§ici: {selector})")
                        break
                        
                except Exception as e:
                    print(f"âš ï¸ SeÃ§ici '{selector}' baÅŸarÄ±sÄ±z: {e}")
                    continue
            
            if not links_found:
                print(f"âš ï¸ Sayfa {page}'de Ã¼rÃ¼n linki bulunamadÄ±")
                break
            
            # Yeni linkleri ekle
            for link in links_found:
                if link not in product_links and len(product_links) < max_products:
                    product_links.append(link)
            
            print(f"ğŸ“Š Toplam {len(product_links)} Ã¼rÃ¼n linki toplandÄ±")
            
            # Sonraki sayfa kontrolÃ¼
            page += 1
            
            # EÄŸer maksimum Ã¼rÃ¼n sayÄ±sÄ±na ulaÅŸtÄ±ysak dur
            if len(product_links) >= max_products:
                print(f"ğŸ¯ Maksimum Ã¼rÃ¼n sayÄ±sÄ±na ({max_products}) ulaÅŸÄ±ldÄ±")
                break
                
        except Exception as e:
            print(f"âŒ Sayfa {page} iÅŸleme hatasÄ±: {e}")
            break
    
    print(f"âœ… Toplam {len(product_links)} Ã¼rÃ¼n linki toplandÄ±")
    return product_links

def parse_product_page(driver, product_url):
    """
    Tek bir Ã¼rÃ¼n sayfasÄ±ndan bilgileri toplar
    BaÅŸlÄ±k, SKU, gÃ¶rseller, varyasyonlar ve mockup tespiti yapar
    """
    print(f"ğŸ“¦ ÃœrÃ¼n sayfasÄ± iÅŸleniyor: {product_url}")
    
    retry_count = 0
    while retry_count < MAX_RETRIES:
        try:
            # SayfayÄ± yÃ¼kle
            driver.get(product_url)
            human_wait()
            
            # Sayfa yÃ¼klenene kadar bekle
            WebDriverWait(driver, 15).until(
                EC.presence_of_element_located((By.TAG_NAME, "body"))
            )
            
            # ÃœrÃ¼n bilgilerini topla
            product_data = {
                "url": product_url,
                "title": "",
                "sku": "",
                "images": [],
                "variations": [],
                "mockup_images": [],
                "missing_sizes": [],
                "image_count": 0
            }
            
            # ÃœrÃ¼n baÅŸlÄ±ÄŸÄ±
            try:
                title_selectors = [
                    "h1.pr-new-br",
                    "h1[data-testid='product-name']",
                    ".pr-new-br",
                    "h1"
                ]
                
                for selector in title_selectors:
                    try:
                        title_element = driver.find_element(By.CSS_SELECTOR, selector)
                        product_data["title"] = title_element.text.strip()
                        if product_data["title"]:
                            break
                    except:
                        continue
                        
            except Exception as e:
                print(f"âš ï¸ BaÅŸlÄ±k bulunamadÄ±: {e}")
            
            # SKU (ÃœrÃ¼n Kodu)
            try:
                sku_selectors = [
                    "[data-testid='product-sku']",
                    ".product-sku",
                    ".sku",
                    "[class*='sku']"
                ]
                
                for selector in sku_selectors:
                    try:
                        sku_element = driver.find_element(By.CSS_SELECTOR, selector)
                        product_data["sku"] = sku_element.text.strip()
                        if product_data["sku"]:
                            break
                    except:
                        continue
                        
            except Exception as e:
                print(f"âš ï¸ SKU bulunamadÄ±: {e}")
            
            # GÃ¶rselleri topla
            try:
                image_selectors = [
                    "img[src*='trendyol']",
                    "img[data-src*='trendyol']",
                    "img[data-lazy*='trendyol']",
                    ".product-image img",
                    "[data-testid='product-image'] img"
                ]
                
                all_images = []
                for selector in image_selectors:
                    try:
                        images = driver.find_elements(By.CSS_SELECTOR, selector)
                        for img in images:
                            # FarklÄ± src Ã¶zelliklerini kontrol et
                            src_attrs = ["src", "data-src", "data-lazy", "data-original"]
                            for attr in src_attrs:
                                img_url = img.get_attribute(attr)
                                if img_url and img_url not in all_images:
                                    all_images.append(img_url)
                                    break
                    except:
                        continue
                
                product_data["images"] = all_images
                product_data["image_count"] = len(all_images)
                
            except Exception as e:
                print(f"âš ï¸ GÃ¶rsel toplama hatasÄ±: {e}")
            
            # Mockup gÃ¶rsellerini tespit et
            try:
                mockup_images = []
                for img_url in product_data["images"]:
                    if is_mockup_by_filename(img_url):
                        mockup_images.append(img_url)
                
                product_data["mockup_images"] = mockup_images
                
            except Exception as e:
                print(f"âš ï¸ Mockup tespit hatasÄ±: {e}")
            
            # VaryasyonlarÄ± topla (Ã¶lÃ§Ã¼ler)
            try:
                variation_selectors = [
                    "ul li",
                    ".variation-item",
                    "[data-testid='variation']",
                    ".size-option",
                    ".option-item"
                ]
                
                variations = []
                for selector in variation_selectors:
                    try:
                        elements = driver.find_elements(By.CSS_SELECTOR, selector)
                        for element in elements:
                            text = element.text.strip()
                            if text and len(text) < 20:  # Ã‡ok uzun metinleri filtrele
                                variations.append(text)
                    except:
                        continue
                
                # TekrarlarÄ± kaldÄ±r ve temizle
                product_data["variations"] = list(set(variations))
                
            except Exception as e:
                print(f"âš ï¸ Varyasyon toplama hatasÄ±: {e}")
            
            # Eksik Ã¶lÃ§Ã¼leri hesapla
            product_data["missing_sizes"] = evaluate_missing_sizes(product_data, EXPECTED_SIZES)
            
            print(f"âœ… ÃœrÃ¼n iÅŸlendi: {product_data['title'][:50]}...")
            return product_data
            
        except TimeoutException:
            retry_count += 1
            print(f"â° Sayfa yÃ¼kleme timeout (deneme {retry_count}/{MAX_RETRIES})")
            if retry_count < MAX_RETRIES:
                human_wait()
                continue
            else:
                print(f"âŒ ÃœrÃ¼n sayfasÄ± yÃ¼klenemedi: {product_url}")
                return None
                
        except Exception as e:
            retry_count += 1
            print(f"âŒ ÃœrÃ¼n sayfasÄ± iÅŸleme hatasÄ± (deneme {retry_count}/{MAX_RETRIES}): {e}")
            if retry_count < MAX_RETRIES:
                human_wait()
                continue
            else:
                return None

def evaluate_missing_sizes(item, expected_sizes):
    """
    Varyasyonlarda beklenen Ã¶lÃ§Ã¼lerin olup olmadÄ±ÄŸÄ±nÄ± kontrol eder
    Eksik Ã¶lÃ§Ã¼leri dÃ¶ndÃ¼rÃ¼r
    """
    missing_sizes = []
    variations_text = " ".join(item.get("variations", [])).lower()
    
    for size in expected_sizes:
        if size.lower() not in variations_text:
            missing_sizes.append(size)
    
    return missing_sizes

def analyze_all_sizes_in_products(results):
    """
    TÃ¼m Ã¼rÃ¼nlerden benzersiz Ã¶lÃ§Ã¼leri toplar ve analiz eder
    Hangi Ã¶lÃ§Ã¼lerin hangi Ã¼rÃ¼nlerde eksik olduÄŸunu gÃ¶sterir
    """
    all_sizes = set()
    
    # TÃ¼m Ã¼rÃ¼nlerden Ã¶lÃ§Ã¼leri topla
    for item in results:
        variations = item.get("variations", [])
        for var in variations:
            # EÄŸer Ã¶lÃ§Ã¼ formatÄ±ysa (Ã¶rn: "30x40", "40x60")
            if 'x' in var.lower() or 'cm' in var.lower() or var.isdigit():
                all_sizes.add(var)
    
    # Eksik Ã¶lÃ§Ã¼ analizi
    size_analysis = {}
    for size in all_sizes:
        size_analysis[size] = {
            'total_products': 0,
            'products_with_this_size': 0,
            'products_without_this_size': [],
            'existence_rate': 0.0
        }
    
    # Her Ã¼rÃ¼n iÃ§in hangi Ã¶lÃ§Ã¼lerin olduÄŸunu kontrol et
    for item in results:
        variations = item.get("variations", [])
        variations_lower = [v.lower() for v in variations]
        
        for size in all_sizes:
            size_analysis[size]['total_products'] += 1
            
            if any(size.lower() in var for var in variations_lower):
                size_analysis[size]['products_with_this_size'] += 1
            else:
                size_analysis[size]['products_without_this_size'].append({
                    'title': item.get('title', 'Bilinmeyen'),
                    'url': item.get('url', '')
                })
    
    # VarlÄ±k oranÄ±nÄ± hesapla
    for size, data in size_analysis.items():
        if data['total_products'] > 0:
            data['existence_rate'] = (data['products_with_this_size'] / data['total_products']) * 100
    
    return size_analysis

def save_results_to_json(results, filename="scraped_products.json"):
    """SonuÃ§larÄ± JSON dosyasÄ±na kaydeder"""
    try:
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ SonuÃ§lar JSON dosyasÄ±na kaydedildi: {filename}")
    except Exception as e:
        print(f"âŒ JSON kaydetme hatasÄ±: {e}")

def main():
    """Ana fonksiyon - tÃ¼m akÄ±ÅŸÄ± Ã§alÄ±ÅŸtÄ±rÄ±r"""
    print("=" * 60)
    print("*** TRENDYOL SATICI SCRAPER - EXCEL RAPORU ***")
    print("=" * 60)
    
    # Komut satÄ±rÄ± argÃ¼manlarÄ±nÄ± kontrol et
    if len(sys.argv) > 1:
        seller_url = sys.argv[1].strip()
        print(f"Komut satirindan URL alindi: {seller_url}")
    else:
        # KullanÄ±cÄ±dan satÄ±cÄ± URL'si al
        seller_url = input("Trendyol satici URL'sini girin (orn: https://www.trendyol.com/magaza/xxxx): ").strip()
    
    if not seller_url:
        print("[HATA] URL girilmedi!")
        return
    
    if "trendyol.com/magaza/" not in seller_url:
        print("[UYARI] URL Trendyol satici sayfasi gibi gorunmuyor!")
        confirm = input("Devam etmek istiyor musunuz? (e/h): ").lower()
        if confirm != 'e':
            return
    
    # ChromeDriver'Ä± baÅŸlat
    driver = None
    try:
        driver = init_driver()
        
        # ÃœrÃ¼n linklerini topla
        product_links = collect_product_links_from_seller(driver, seller_url)
        
        if not product_links:
            print("âŒ HiÃ§ Ã¼rÃ¼n linki bulunamadÄ±!")
            return
        
        print(f"\nğŸ” {len(product_links)} Ã¼rÃ¼n sayfasÄ± iÅŸlenecek...")
        
        # Her Ã¼rÃ¼n sayfasÄ±nÄ± iÅŸle
        results = []
        for i, product_url in enumerate(product_links, 1):
            print(f"\nğŸ“¦ [{i}/{len(product_links)}] ÃœrÃ¼n iÅŸleniyor...")
            
            product_data = parse_product_page(driver, product_url)
            if product_data:
                results.append(product_data)
            
            # Ä°lerleme gÃ¶ster
            if i % 10 == 0:
                print(f"ğŸ“Š Ä°lerleme: {i}/{len(product_links)} Ã¼rÃ¼n iÅŸlendi")
        
        print(f"\nâœ… Toplam {len(results)} Ã¼rÃ¼n baÅŸarÄ±yla iÅŸlendi!")
        
        # SonuÃ§larÄ± kaydet
        save_results_to_json(results)
        
        # Excel raporu oluÅŸtur
        print("ğŸ“Š Excel raporu oluÅŸturuluyor...")
        generate_excel_report(results, "rapor.xlsx")
        
        print("\nğŸ‰ Ä°ÅŸlem tamamlandÄ±!")
        print("ğŸ“ Ã‡Ä±ktÄ± dosyalarÄ±:")
        print("   - scraped_products.json")
        print("   - rapor.xlsx")
        
    except KeyboardInterrupt:
        print("\nâ¹ï¸ Ä°ÅŸlem kullanÄ±cÄ± tarafÄ±ndan durduruldu")
        
    except Exception as e:
        print(f"\nâŒ Genel hata: {e}")
        
    finally:
        if driver:
            print("ğŸ”š TarayÄ±cÄ± kapatÄ±lÄ±yor...")
            driver.quit()

if __name__ == "__main__":
    main()
